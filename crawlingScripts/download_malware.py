import requests
from bs4 import BeautifulSoup
import numpy as np
import unicodedata
import urllib
import csv


malwareURLs = "url_malware"
file_m = open(malwareURLs, 'wb')
data = []

#Strips unnecessary information from the url
def processURL(url):
	u = url.split('/')[0]
	return u	

def extractFromURL(url):
	url = urllib.urlopen(url)

	soup = BeautifulSoup(url)

	tr = soup.findAll('tr', {"class" : ""})

	for r in tr:
		row = []
		td = r.findAll('td')
	
		for d in range(len(td)):
			if d == 1:
				url = unicodedata.normalize('NFKD', td[d].text).encode('ascii','ignore')
				if(url == '-'):
					continue
				u = processURL(url)			
				row.append(u)
			elif d == 2:
				ip = unicodedata.normalize('NFKD', td[d].text).encode('ascii','ignore')
				row.append(ip)
			elif d == 6:
				asn = unicodedata.normalize('NFKD', td[d].text).encode('ascii','ignore')
				row.append(asn)

		#ignore entries with missing values
		if(len(row) < 3):
			continue

		data.append(row)

	with open('m_file', 'a') as fp:
		a = csv.writer(fp, delimiter = ',')
		a.writerows(data)

pageNumber = 0

#url = "file:///home/yousuff/DeMalfier/output"
while(pageNumber <= 33):
	url = "http://www.malwaredomainlist.com/mdl.php?inactive=&sort=Date&search=&colsearch=All&ascordesc=DESC&quantity=100&page="+ str(pageNumber)
	print "Extractign from page : " + str(pageNumber)
	extractFromURL(url)
	pageNumber += 1


